{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# PDF Parsing:\n",
    "The objective of this notebook is to develop a pdf parser and arabic text extractor.  \n",
    "Parsing PDF could be treated as 5-steps process, done respectively in the following order -after decompressing the pdf file- :\n",
    "\n",
    "1. Traversing PDF logical tree and find all Page objects in that way you guarantees pages ordering is correct.\n",
    "Then for each Page:  \n",
    "2. Retrieve fonts information and ToUnicode tables.   \n",
    "3. Retrieve contents.   \n",
    "4. Decode contents. \n",
    "5. Position the text into their right orders. \n",
    "\n",
    "\n",
    "The implementation here is optimized for parsing pdf with CID fonts ”Type0”,  where fonts are explicitly referenced by the Page object and the ToUnicode tables are embedded within the pdf.\n",
    "\n",
    "#### Helpful resources:\n",
    "- [`pdf parsing - understanding pdfs`](https://docs.google.com/document/d/1gfxrJyJlx4NPCdnrElcwRx7ZByCKBO3RFrzmkKEUxuo/edit?usp=sharing)\n",
    "- [PDFReference](https://www.adobe.com/content/dam/acom/en/devnet/pdf/pdfs/pdf_reference_archives/PDFReference.pdf)\n",
    "- [PDF Explained](https://learning.oreilly.com/library/view/pdf-explained/9781449321581/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import re\n",
    "import numpy as np\n",
    "from binascii import unhexlify, hexlify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Retrievers Functions\n",
    "Retrieve related data such as content streams, ToUnicode tables.\n",
    "\n",
    "#### TODO:\n",
    "- need to change the way of naming fonts, not all font start with C2_X. <mark> [Done] </mark>\n",
    "- need to consider beggingofrange alongside with beggingofchar\n",
    "- need to change the way of retrieving content and consider the case of an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fonts(page):\n",
    "    \"\"\"\n",
    "    Retrieving fonts from a given page\n",
    "    #Args:\n",
    "        - Page object\n",
    "    #Returns:\n",
    "        - Fonts obejcts Id's numbers\n",
    "    \"\"\"\n",
    "    fonts_ref = [font.split(' ')[1]       for font in re.findall('C2_[0-9]\\s[0-9]+', page.split('Font')[1]) ] \n",
    "    return fonts_ref\n",
    " \n",
    "    \n",
    "def get_cmap(font_ref,pdf_content):\n",
    "    \"\"\"\n",
    "    Retrieving ToUnicode table\n",
    "    #Args:\n",
    "        - Font object id \n",
    "        - Decompressed pdf file\n",
    "    #Returns:\n",
    "        - ToUnicode table saved in a dictionary\n",
    "    \"\"\"\n",
    "    # Finding cmap reference that associated to a specific font\n",
    "    cmap_ref = re.findall(re.compile(fr'(obj\\s{font_ref}\\s0\\n[a-zA-Z0-9\\n\\s:,.<_/\\[\\]+-]+/ToUnicode\\s)([0-9]+)'),pdf_content)[0][1]\n",
    "    \n",
    "    # Traverse to cmap object and retrieve the cmap and save it into a dictionary\n",
    "    cmap = re.findall(re.compile(fr\"\"\"(obj\\s{cmap_ref}\\s0\\n[a-zA-Z0-9\\n\\s:,.<>_+-/\\[\\]\\\\']+)(nbegincmap.*?nendcmap)\"\"\"),pdf_content)[0][1]\n",
    "    cmap_as_list = re.findall(re.compile('<[a-fA-F0-9]+> <[a-fA-F0-9]+>'), cmap)\n",
    "    return {encode.split()[0].replace('<','').replace('>',''):unhexlify(encode.split()[1].replace('<','').replace('>','')).decode('utf-16-be') for encode in cmap_as_list}\n",
    "\n",
    "\n",
    "def get_content(page,pdf_content):\n",
    "    \"\"\"\n",
    "    Retriving content obejct\n",
    "    #Args:\n",
    "        - Page object\n",
    "        - Decompressed pdf file\n",
    "    #Returns:\n",
    "        - Page content \n",
    "    \"\"\"\n",
    "    contents_ref = page.split('Contents ')[1].split(' ')[0]\n",
    "    try:\n",
    "        content = re.findall(re.compile(fr\"\"\"(obj\\s{contents_ref}\\s0\\n[a-zA-Z0-9\\n\\s:,.<>_+-/\\[\\]\\\\()]+)('.*?')\"\"\"),pdf_content)[0][1]\n",
    "    except:\n",
    "        content = re.findall(re.compile(fr\"\"\"(obj\\s{contents_ref}\\s0\\n[a-zA-Z0-9\\n\\s:,.<>_+-/\\[\\]\\\\()]+)(\".*?\")\"\"\"),pdf_content)[0][1]\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Function\n",
    "Decoding the text is done by finding the text associated font ToUnicode table, where the table  \n",
    "Keys represent font encoding and values represent the corresponding unicode characters. \n",
    "\n",
    "E.x.  \n",
    "/C2_0 FT   <\"AAAABBBB\"> Tj  \n",
    "\n",
    "The font name is `C2_0`    \n",
    "The dictnory **instance_mapping[`C2_0`]** contains the ToUnicode table for `C2_0`  \n",
    "and the mapping would be **instance_mapping[`C2_0`][AAAA]**\n",
    "\n",
    "AAAA maps to unicode xxxx  \n",
    "BBBB  maps to unicode zzzz\n",
    " \n",
    " \n",
    "#### TODO:\n",
    "- consider different encoding cases such as \\xAAAA, this might be done by checking the font type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_content(tag,instance_mapping,used_font):\n",
    "    \"\"\"\n",
    "    #Args:\n",
    "        - Text tags.i.e. <XXXX> inside a Tj/J\n",
    "        - Font dictionary formatted as {font_name: {font_code:unicode}}\n",
    "    #Return:\n",
    "        - Decoded text\n",
    "    \"\"\"\n",
    "    t = \"\"\n",
    "    tag = tag.replace(\"<\",\"\")\n",
    "    tag = tag.replace(\">\",\"\")\n",
    "    for i in range(0,len(tag), 4):\n",
    "        try:\n",
    "            t= instance_mapping[used_font][tag[i:i+4]]+t\n",
    "        except:\n",
    "            pass\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positioning Functions\n",
    "Get text strings coordinates and update text matrix. \n",
    "\n",
    "The suggested approach is to extract all TJ/j with their coordinates, store them in a nested dictionary where keys represent y,x coordinates and then do the sorting.  \n",
    "The calculations are done as explained in the `pdf parsing - understanding pdfs` document\n",
    "#### TODO:\n",
    "- remove number of page <mark> [Done] </mark>\n",
    "- consider cropbox and page ranges, check for content if it's in the page cropbox or not\n",
    "- TJ positioning\n",
    "\n",
    "#### Things to highlight:\n",
    "- Due to the way of how float is stored in momery and how it is affecting the positioning calculations, I needed to round  x and y to the nearest integer when using them as keys only, but the calculations are not rounded.\n",
    "- did a quick solution to cropbox problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Bt contines more than one Tm\n",
    "# added .split('\\\\n')\n",
    "def get_text_metrics(bt,text_matrix):\n",
    "    \"\"\"\n",
    "    Get the updated text matrix\n",
    "    #Arg:\n",
    "        -bt: BT tags or text string \"TJ/j tags\"\n",
    "        -text_matrix : pre initialized text matrix\n",
    "    #Return:\n",
    "        - a: horizontal scale\n",
    "        - b: vertical scale\n",
    "        - c: horizontal rotation\n",
    "        - d: vertical rotation\n",
    "        - e: horizontal position -  x \n",
    "        - f: vertical position - y\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'Tm' in bt:\n",
    "        Tm = bt.split('Tm')[0].split('\\\\n')[-1]\n",
    "        a,b,c,d,e,f = list(map(float,Tm.split()[-6:]))\n",
    "        return np.array([[a,b,0],\n",
    "                     [c,d,0],\n",
    "                     [e,f,1]])\n",
    "    else:\n",
    "        return text_matrix\n",
    "\n",
    "\n",
    "def get_text_coordinate(Tj, text_matrix,Tl):\n",
    "    \"\"\"\n",
    "    Get corresponding text coordinates\n",
    "    #Arg:\n",
    "        - Text string either Tj or TJ\n",
    "        - text matrix\n",
    "        - Text leading \"line spacing\"\n",
    "    #Return:\n",
    "        - Text string x position\n",
    "        - Text string y position\n",
    "        - Updated text leading \n",
    "    \"\"\"\n",
    "    if 'Td' in Tj:\n",
    "        for Td in Tj.split(' Td')[:-1]:\n",
    "            Tx = float(Td.split('\\\\n')[-1].split()[-2])\n",
    "            Ty = float(Td.split('\\\\n')[-1].split()[-1])\n",
    "            Tlm = np.array([[1,0,0],\n",
    "                            [0,1,0],\n",
    "                            [Tx,Ty,1]])\n",
    "            text_matrix =  Tlm.dot(text_matrix)  \n",
    "                    \n",
    "    elif 'TD' in Tj:\n",
    "        for TD in Tj.split(' TD')[:-1]:\n",
    "            # update text leading\n",
    "            Tl = float(TD.split('\\\\n')[-1].split()[-1])\n",
    "            # update x and y \n",
    "            Tx = float(TD.split('\\\\n')[-1].split()[-2])\n",
    "            Ty = float(TD.split('\\\\n')[-1].split()[-1])\n",
    "            Tlm = np.array([[1,0,0],\n",
    "                            [0,1,0],\n",
    "                            [Tx,Ty,1]])\n",
    "            text_matrix = Tlm.dot(text_matrix)\n",
    "            \n",
    "    elif 'T*' in Tj:\n",
    "        Tx =0 \n",
    "        Ty = Tl\n",
    "        Tlm = np.array([[1,0,0],\n",
    "                        [0,1,0],\n",
    "                        [Tx,Ty,1]])\n",
    "        text_matrix = Tlm.dot(text_matrix)\n",
    "        \n",
    "    return (text_matrix,Tl)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def store_text_with_coordinates(Tx,Ty,Tpage,scale,text,content_positioning):\n",
    "    \"\"\"\n",
    "    Store decoded text into a dictionary to postion text \n",
    "    into its right palce i.e {page_number:{y:{x:text}}}\n",
    "    #Args:\n",
    "        - Tx: represent offset in a line\n",
    "        - Ty:represent line\n",
    "        - page number: to be romved\n",
    "        - decoded text: readable text\n",
    "        - content_positioning: dictionary in which to store text\n",
    "    #Return:\n",
    "        None, It applys changes directly to the dictionary\n",
    "    \"\"\"\n",
    "    if (Tx > 0 and Ty > 0):\n",
    "        Tx = int(Tx)\n",
    "        Ty = int(Ty)\n",
    "\n",
    "        page = content_positioning.setdefault(Tpage,{})\n",
    "        y = page.setdefault(Ty,{})\n",
    "        try:\n",
    "            y[Tx] = text +y[Tx]\n",
    "        except:\n",
    "            x = y.setdefault(Tx,text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Function:\n",
    "Arrange text using their x y cooreinates.\n",
    "\n",
    "#### TODO:\n",
    "- find a method to position diacritics correctly. The problem here is that pdf place diacritics alone so their y-coordinates will be higher than the words y-coordinate which will cause them to appear before the word, one way to slove this is by rounding and combining lines where the distance between them is less than line spaceing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arranging_text(text_with_coordinates):\n",
    "    text = \"\"\n",
    "    for page in sorted(text_with_coordinates):\n",
    "        for line in sorted(text_with_coordinates[page],reverse =True):\n",
    "            for word in sorted(text_with_coordinates[page][line],reverse =True):\n",
    "                text += text_with_coordinates[page][line][word]\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading decompressed pdf file\n",
    "file_name = \"5.txt\"\n",
    "with open(f\"1435_decompressed/{file_name}\", \"r\") as f:\n",
    "    pdf_content = f.read() \n",
    "f.close()\n",
    "\n",
    "# Finding all Page objects - Step 1\n",
    "page_tags = re.findall(re.compile(r\"\"\"obj\\s[0-9]+\\s0\\n\\sType:\\s/Page[a-zA-Z0-9\\n\\s:,.<>_/\\[\\]]+Contents[a-zA-Z0-9\\n\\s:,.<>_/\\[\\]]+Font[a-zA-Z0-9\\n\\s:,.<>_/\\[\\]]+\"\"\"), pdf_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "store_text_with_coordinates() missing 1 required positional argument: 'content_positioning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0589c1e8d829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtext_tag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_tag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstance_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_used_font\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mstore_text_with_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTpage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_with_coordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: store_text_with_coordinates() missing 1 required positional argument: 'content_positioning'"
     ]
    }
   ],
   "source": [
    "full_docs_text = ''\n",
    "for page in page_tags:\n",
    "\n",
    "\n",
    "    # Retriving fonts for encoding - Step 2\n",
    "    fonts_mapping_dic = {}\n",
    "    instance_mapping = {}\n",
    "\n",
    "\n",
    "    fonts_ref = get_fonts(page)\n",
    "    for font_ref, num in zip(fonts_ref, range(len(fonts_ref))):\n",
    "        if font_ref not in fonts_mapping_dic:\n",
    "            fonts_mapping_dic[font_ref] = get_cmap(font_ref, pdf_content)\n",
    "\n",
    "        instance_mapping[f'C2_{num}'] = fonts_mapping_dic[font_ref]\n",
    "\n",
    "    # Retriving content - Step 3\n",
    "    content = get_content(page,pdf_content)\n",
    "    cropbox_x = float(re.findall('[\\d+\\.\\d+]+', page.split('/CropBox')[1])[:4][-2])\n",
    "    cropbox_y = float(re.findall('[\\d+\\.\\d+]+', page.split('/CropBox')[1])[:4][-1])\n",
    "\n",
    "    # Decodeing and positioning\n",
    "    BTs = content.split(\"BT\")\n",
    "    text_with_coordinates = dict()\n",
    "    Tpage = 0  # Initial value  -PDF specification- \n",
    "    Tm = np.array([[1,0,0],  # Initial value: 0 -PDF specification-\n",
    "               [0,1,0],\n",
    "               [0,0,1]])  \n",
    "    Tl = 0 # Initial value: 0 -PDF specification-\n",
    "    for j in range(1,len(BTs)):\n",
    "        bt = BTs[j]\n",
    "\n",
    "        for Tj in bt.split('Tj'):\n",
    "\n",
    "            # Finding text string in TJ \n",
    "            if 'TJ' in Tj:\n",
    "                for TJ in Tj.split('TJ')[:-1]:\n",
    "                    try:\n",
    "                        used_font = re.findall(re.compile(r\"\"\"(C2_[0-9]+)\\s\"\"\"), TJ)[0]\n",
    "                        last_used_font = used_font\n",
    "                    except:\n",
    "                        pass\n",
    "                    # Get text metrics\n",
    "                    Tm = get_text_metrics(TJ,Tm)               \n",
    "                    Tm,Tl = get_text_coordinate(TJ,Tm,Tl)\n",
    "                    # Finding text strings\n",
    "                    text_tags = re.findall(\"<[0-9a-fA-F]+>\", TJ)\n",
    "                    for text_tag in text_tags:\n",
    "                        text = decode_content(text_tag,instance_mapping,last_used_font)\n",
    "                        store_text_with_coordinates(Tm[2][0],Tm[2][1],Tpage,Tm[0][0],text,text_with_coordinates)\n",
    "\n",
    "\n",
    "\n",
    "            # Finding text string in Tj\n",
    "            Tj_ = Tj.split('TJ')[-1]\n",
    "            try:\n",
    "                used_font = re.findall(re.compile(r\"\"\"(C2_[0-9]+)\\s\"\"\"), Tj_)[0]\n",
    "                last_used_font = used_font\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Get text metrics\n",
    "            Tm = get_text_metrics(Tj_,Tm)\n",
    "            Tm,Tl = get_text_coordinate(Tj_,Tm,Tl)\n",
    "            # Finding text strings\n",
    "            text_tags = re.findall(\"<[0-9a-fA-F]+>\", Tj_)\n",
    "            for text_tag in text_tags:\n",
    "                text = decode_content(text_tag,instance_mapping,last_used_font)\n",
    "                store_text_with_coordinates(Tm[2][0],Tm[2][1],Tpage,Tm[0][0],text,text_with_coordinates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    full_docs_text += arranging_text(text_with_coordinates)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moj_env",
   "language": "python",
   "name": "moj_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
